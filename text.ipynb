{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "cwd = os.path.abspath(os.path.curdir)\n",
    "sys.path.append(cwd)  # workplace\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from causallearn.graph.GraphNode import GraphNode\n",
    "import copy\n",
    "from causallearn.graph.Dag import Dag\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def ini_nodes(adj_df):\n",
    "    nodes = []\n",
    "    for i in range(len(adj_df[0,:])):\n",
    "        nodes.append(GraphNode(str(i)))\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def adj2dag(adj_df):\n",
    "    G = nx.from_numpy_array(adj_df, create_using=nx.DiGraph)\n",
    "    nodes = ini_nodes(adj_df)\n",
    "    dag = Dag(nodes)\n",
    "    for i,j in list(G.edges()):\n",
    "        dag.add_directed_edge(nodes[i], nodes[j])\n",
    "    return dag,nodes\n",
    "\n",
    "def remove_edge(index_x, index_y,nodes, dag):\n",
    "    dag_rm = copy.deepcopy(dag)\n",
    "    dag_rm.remove_connecting_edge(nodes[index_x], nodes[index_y])\n",
    "    return dag_rm\n",
    "\n",
    "def get_all_xy_edges(dag,nodes):\n",
    "    x_ls = []\n",
    "    y_ls = []\n",
    "    for e in list(dag.get_graph_edges()):        \n",
    "        index_x = int(e.get_node1().get_name())\n",
    "        index_y = int(e.get_node2().get_name())\n",
    "        x_ls.append(index_x)\n",
    "        y_ls.append(index_y)\n",
    "    dir = np.array([x_ls,y_ls])\n",
    "    return dir.T\n",
    "\n",
    "def get_eva_xy_dirs(dag,nodes):\n",
    "    x_ls = []\n",
    "    y_ls = []\n",
    "    for e in list(dag.get_graph_edges()):        \n",
    "        index_x = int(e.get_node1().get_name())\n",
    "        index_y = int(e.get_node2().get_name())\n",
    "        dag_rm = remove_edge(index_x, index_y,nodes, dag)\n",
    "        # print(e.get_node1(),e.get_node2(),dag_rm.is_dseparated_from(nodes[index_x],nodes[index_y],set()))\n",
    "        if dag_rm.is_dseparated_from(nodes[index_x],nodes[index_y],set()):\n",
    "            x_ls.append(index_x)\n",
    "            y_ls.append(index_y)\n",
    "    dir = np.array([x_ls,y_ls])\n",
    "    return dir.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'lu'\n",
    "for sim_seed in range(100,110):\n",
    "    with open(f'./eval_llms/data/table/cdir_{sim_seed}_questions.txt', 'w') as file:\n",
    "        adj_path = f'./data/sim_{dataname}/{sim_seed}/generated_graph_target.csv'\n",
    "        adj_df = pd.read_csv(adj_path)\n",
    "        dag,nodes = adj2dag(adj_df.to_numpy())\n",
    "        xy_edges = get_all_xy_edges(dag,nodes)\n",
    "        eva_xy_dirs =  get_eva_xy_dirs(dag,nodes)\n",
    "        for pair in eva_xy_dirs:    \n",
    "            file.write(f'Between V{pair[0]} and V{pair[1]}, is V{pair[0]} the cause?\\n')\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cz(cz):\n",
    "    cz_text = ''\n",
    "    for element in cz:\n",
    "        cz_text += 'V' + str(element) \n",
    "    return cz_text\n",
    "\n",
    "\n",
    "def text_ci(ciset):\n",
    "    question_ls = []\n",
    "    for cis in ciset:\n",
    "        if len(cis[2]) == 0:\n",
    "            ci_text = f'Are V{cis[0]} and V{cis[1]} independent from each other?'\n",
    "        else:\n",
    "            cz_text =text_cz(cis[2])\n",
    "            ci_text = f'Are V{cis[0]} and V{cis[1]} conditionally independent given {cz_text}?'    \n",
    "        question_ls.append(ci_text)\n",
    "    return question_ls\n",
    "\n",
    "\n",
    "def text_dsep(ciset):\n",
    "    question_ls = []\n",
    "    for cis in ciset:\n",
    "        if len(cis[2]) == 0:\n",
    "            ci_text = f'Are V{cis[0]} and V{cis[1]} d-seperated?'\n",
    "        else:\n",
    "            cz_text =text_cz(cis[2])\n",
    "            ci_text = f'Are V{cis[0]} and V{cis[1]} d-seperated given {cz_text}?'    \n",
    "        question_ls.append(ci_text)\n",
    "    return question_ls\n",
    "\n",
    "from eval_llms.src.causal_eval.helper import get_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'lu'\n",
    "for sim_seed in range(100,110):\n",
    "    adj_path = f'./data/sim_{dataname}/{sim_seed}/generated_graph_target.csv'\n",
    "    adj_df = pd.read_csv(adj_path)\n",
    "    _,_,conditional_independent_set,_,conditional_dependent_set = get_sets(adj_df.to_numpy())\n",
    "\n",
    "    ci_sets = text_dsep(conditional_independent_set)\n",
    "    nci_set = text_dsep(conditional_dependent_set)\n",
    "    with open(f'./eval_llms/data/graph/{sim_seed}_questions.txt', 'w') as file:\n",
    "        for q in ci_sets:\n",
    "            file.write(q)\n",
    "            file.write('\\n')\n",
    "        for q in nci_set:\n",
    "            file.write(q)\n",
    "            file.write('\\n')\n",
    "\n",
    "    with open(f'./eval_llms/data/graph/{sim_seed}_answers.txt', 'w') as file:\n",
    "        for q in ci_sets:\n",
    "            file.write('yes')\n",
    "            file.write('\\n')\n",
    "        for q in nci_set:\n",
    "            file.write('no')\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'lu'\n",
    "for sim_seed in range(100,110):\n",
    "    adj_path = f'./data/sim_{dataname}/{sim_seed}/generated_graph_target.csv'\n",
    "    adj_df = pd.read_csv(adj_path)\n",
    "    _,_,conditional_independent_set,_,conditional_dependent_set = get_sets(adj_df.to_numpy())\n",
    "\n",
    "    ci_sets = text_ci(conditional_independent_set)\n",
    "    nci_set = text_ci(conditional_dependent_set)\n",
    "    with open(f'./eval_llms/data/table/{sim_seed}_questions.txt', 'w') as file:\n",
    "        for q in ci_sets:\n",
    "            file.write(q)\n",
    "            file.write('\\n')\n",
    "        for q in nci_set:\n",
    "            file.write(q)\n",
    "            file.write('\\n')\n",
    "\n",
    "    with open(f'./eval_llms/data/table/{sim_seed}_answers.txt', 'w') as file:\n",
    "        for q in ci_sets:\n",
    "            file.write('yes')\n",
    "            file.write('\\n')\n",
    "        for q in nci_set:\n",
    "            file.write('no')\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'lu'\n",
    "for sim_seed in range(100,110):\n",
    "    adj_path = f'./data/sim_{dataname}/{sim_seed}/generated_graph_target.csv'\n",
    "    adj_df = pd.read_csv(adj_path)\n",
    "    _,_,conditional_independent_set,_,conditional_dependent_set = get_sets(adj_df.to_numpy())\n",
    "\n",
    "    ci_sets = text_ci(conditional_independent_set)\n",
    "    nci_set = text_ci(conditional_dependent_set)\n",
    "    with open(f'./eval_llms/data/{sim_seed}_questions.txt', 'w') as file:\n",
    "        for q in ci_sets:\n",
    "            file.write(q)\n",
    "            file.write('\\n')\n",
    "        for q in nci_set:\n",
    "            file.write(q)\n",
    "            file.write('\\n')\n",
    "\n",
    "    with open(f'./eval_llms/data/{sim_seed}_answers.txt', 'w') as file:\n",
    "        for q in ci_sets:\n",
    "            file.write('yes')\n",
    "            file.write('\\n')\n",
    "        for q in nci_set:\n",
    "            file.write('no')\n",
    "            file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
